{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MINDS JSON-LD writer\n",
    "This script produces a collection of MINDS JSONs, which describe the dataset according to HBP minimal metadata criteria (MINDS v1).   \n",
    "For more information please visit:   \n",
    "https://github.com/HumanBrainProject/openMINDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required packages\n",
    "import os\n",
    "import pandas as pd\n",
    "from braceexpand import braceexpand\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read study participant information from BIDS participants.tsv\n",
    "Alternatively, participant information can be manually loaded into the 'participants_tsv' variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify path to BIDS dataset\n",
    "BIDSroot = \"/path/to/BIDS\"\n",
    "# Read participants.tsv\n",
    "participants_tsv = pd.read_csv(BIDSroot+\"/participants.tsv\", sep='\\t',dtype={'participant_id': str})\n",
    "\n",
    "# specify path where output MINDS JSON-LD schema shall be stored\n",
    "MINDSroot = \"/path/to/output\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate output directory structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in list(braceexpand(MINDSroot+'/core/{dataset,specimengroup}/v1.0.0')): os.makedirs(x, exist_ok=True)\n",
    "os.makedirs(MINDSroot+'/experiment/subject/v1.0.0', exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define helper functions that write JSONs from schemas\n",
    "\n",
    "The function *openMINDSschemaWriter* accepts arguments for schema type, etc.\n",
    "The class *baseSchema* defines attributes common to all schemas. It also defines a default function for naming & writing JSON files (files are named: schemaName-0X.json)\n",
    "\n",
    "All further classes are based on the *baseSchema* class. They define additional attributes (fill the keys of the specific schemas (JSON templates)). Additionally, in some cases, they may implement a modified function to rename JSONs; JSONs will be named according to the schema's *name* field.\n",
    "\n",
    "Note: (un)comment lines related to the key-value pairs that should (not) appear in the resulting JSON files and modify fields according to the features your data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def openMINDSschemaWriter(schema_type, MINDSroot, schema_dir, schema_name, schema_json, dataRoot, relatedIRI=\"\"):\n",
    "    if schema_type == \"person\":\n",
    "        return personSchema(schema_type, MINDSroot, schema_dir, schema_name, schema_json, dataRoot, relatedIRI)\n",
    "    if schema_type == \"sex\":\n",
    "        return sexSchema(schema_type, MINDSroot, schema_dir, schema_name, schema_json, dataRoot, relatedIRI)\n",
    "    if schema_type == \"species\":\n",
    "        return speciesSchema(schema_type, MINDSroot, schema_dir, schema_name, schema_json, dataRoot, relatedIRI)\n",
    "    if schema_type == \"authority\":\n",
    "        return authoritySchema(schema_type, MINDSroot, schema_dir, schema_name, schema_json, dataRoot, relatedIRI)\n",
    "    if schema_type == \"approval\":\n",
    "        return approvalSchema(schema_type, MINDSroot, schema_dir, schema_name, schema_json, dataRoot, relatedIRI)\n",
    "    if schema_type == \"method\":\n",
    "        return methodsSchema(schema_type, MINDSroot, schema_dir, schema_name, schema_json, dataRoot, relatedIRI)\n",
    "    if schema_type == \"preparation\":\n",
    "        return preparationSchema(schema_type, MINDSroot, schema_dir, schema_name, schema_json, dataRoot, relatedIRI)\n",
    "    if schema_type == \"activity\":\n",
    "        return activitySchema(schema_type, MINDSroot, schema_dir, schema_name, schema_json, dataRoot, relatedIRI)\n",
    "    if schema_type == \"agecategory\":\n",
    "        return agecategorySchema(schema_type, MINDSroot, schema_dir, schema_name, schema_json, dataRoot, relatedIRI)\n",
    "    if schema_type == \"specimengroup\":\n",
    "        return specimengroupSchema(schema_type, MINDSroot, schema_dir, schema_name, schema_json, dataRoot, relatedIRI)\n",
    "    if schema_type == \"simulator\":\n",
    "        return simulatorSchema(schema_type, MINDSroot, schema_dir, schema_name, schema_json, dataRoot, relatedIRI)\n",
    "    if schema_type == \"subject\":\n",
    "        return subjectSchema(schema_type, MINDSroot, schema_dir, schema_name, schema_json, dataRoot, relatedIRI)\n",
    "    if schema_type == \"dataset\":\n",
    "        return datasetSchema(schema_type, MINDSroot, schema_dir, schema_name, schema_json, dataRoot, relatedIRI)\n",
    "\n",
    "class baseSchema:\n",
    "    def __init__(self, schema_type, MINDSroot, schema_dir, schema_name, schema_json, dataRoot, relatedIRI):\n",
    "        self.schema_type = schema_type\n",
    "        self.schema_dir = MINDSroot + schema_dir\n",
    "        self.schema_name = schema_name\n",
    "        self.schema_json = schema_json\n",
    "        self.relatedIRI = relatedIRI\n",
    "        self.fileNum = str(len([file for file in os.listdir(self.schema_dir) if os.path.isfile(os.path.join(self.schema_dir, file))]) + 1).zfill(3)\n",
    "    def writeJSON(self):\n",
    "        #generic JSON naming scheme [<schemaName>-0X.json]. override in specific class if \"name\" naming required.\n",
    "        with open(self.schema_dir+\"/\"+self.schema_type+\"-\"+self.fileNum+\".json\",\"w\") as f:\n",
    "            json.dump(self.schema_json, f, indent=4)\n",
    "\n",
    "class personSchema(baseSchema):\n",
    "    def fillJSON(self):\n",
    "        self.schema_json[\"@type\"] = \"https://schema.hbp.eu/minds/\"+self.schema_type+\".schema.json\"\n",
    "        self.schema_json[\"@id\"] = \"minds\"+ self.schema_dir.split(MINDSroot,1)[1] + \"/\" + self.schema_type + \"-\" + self.fileNum + \".json\"\n",
    "        self.schema_json[\"name\"] = self.schema_name\n",
    "        shortName = \"\"\n",
    "        shortName = shortName + self.schema_name.split(\",\")[0] + \", \"\n",
    "        for w in self.schema_name.split(\",\")[1].split():\n",
    "            shortName = shortName + w[0].upper() + \". \"\n",
    "        shortName.rstrip()\n",
    "        self.schema_json[\"shortName\"] = shortName\n",
    "\n",
    "class sexSchema(baseSchema):\n",
    "    def fillJSON(self):\n",
    "        self.schema_json[\"@type\"] = \"https://schema.hbp.eu/minds/\"+self.schema_type+\".schema.json\"\n",
    "        self.schema_json[\"@id\"] = \"minds\"+ self.schema_dir.split(MINDSroot,1)[1] + \"/\" + self.schema_type + \"-\" + self.fileNum + \".json\"\n",
    "        self.schema_json[\"name\"] = self.schema_name\n",
    "    def writeJSON(self): #overwrite baseSchema \"writeJSON\". #name.\n",
    "        with open(self.schema_dir+\"/\"+self.schema_name+\".json\",\"w\") as f:\n",
    "            json.dump(self.schema_json, f, indent=4)\n",
    "\n",
    "class speciesSchema(baseSchema):\n",
    "    def fillJSON(self):\n",
    "        self.schema_json[\"@type\"] = \"https://schema.hbp.eu/minds/\"+self.schema_type+\".schema.json\"\n",
    "        self.schema_json[\"@id\"] = \"minds\"+ self.schema_dir.split(MINDSroot,1)[1] + \"/\" + self.schema_type + \"-\" + self.fileNum + \".json\"\n",
    "        self.schema_json[\"name\"] = self.schema_name\n",
    "        self.schema_json[\"ontologicalTerm\"] = [{\"@id\": \"ontologies/core/metazoa/v1.0.0/63b90ba0-66be-4969-8a6a-d19ebea01115\"}]\n",
    "    def writeJSON(self): #overwrite baseSchema \"writeJSON\". #name.\n",
    "        with open(self.schema_dir+\"/homo-sapiens.json\",\"w\") as f:\n",
    "            json.dump(self.schema_json, f, indent=4)\n",
    "\n",
    "class authoritySchema(baseSchema):\n",
    "    def fillJSON(self):\n",
    "        self.schema_json[\"@type\"] = \"https://schema.hbp.eu/minds/\"+self.schema_type+\".schema.json\"\n",
    "        self.schema_json[\"@id\"] = \"minds\"+ self.schema_dir.split(MINDSroot,1)[1] + \"/\" + self.schema_type + \"-\" + self.fileNum + \".json\"\n",
    "        self.schema_json[\"name\"] = self.schema_name\n",
    "\n",
    "class approvalSchema(baseSchema):\n",
    "    def fillJSON(self):\n",
    "        self.schema_json[\"@type\"] = \"https://schema.hbp.eu/minds/\"+self.schema_type+\".schema.json\"\n",
    "        self.schema_json[\"@id\"] = \"minds\"+ self.schema_dir.split(MINDSroot,1)[1] + \"/\" + self.schema_type + \"-\" + self.fileNum + \".json\"\n",
    "        self.schema_json[\"name\"] = self.schema_name\n",
    "        self.schema_json[\"generatedBy\"] = [{\"@id\": \"minds/ethics/authority/v1.0.0/\"+file} for file in os.listdir(MINDSroot + \"/ethics/authority/v1.0.0\")]\n",
    "\n",
    "class methodsSchema(baseSchema):\n",
    "    def fillJSON(self):\n",
    "        self.schema_json[\"@type\"] = \"https://schema.hbp.eu/minds/\"+self.schema_type+\".schema.json\"\n",
    "        self.schema_json[\"@id\"] = \"minds\"+ self.schema_dir.split(MINDSroot,1)[1] + \"/\" + self.schema_type + \"-\" + self.fileNum + \".json\"\n",
    "        self.schema_json[\"name\"] = self.schema_name\n",
    "        self.schema_json[\"relatedIRI\"] = self.relatedIRI\n",
    "\n",
    "class preparationSchema(baseSchema):\n",
    "    def fillJSON(self):\n",
    "        self.schema_json[\"@type\"] = \"https://schema.hbp.eu/minds/\"+self.schema_type+\".schema.json\"\n",
    "        self.schema_json[\"@id\"] = \"minds\"+ self.schema_dir.split(MINDSroot,1)[1] + \"/\" + self.schema_type + \"-\" + self.fileNum + \".json\"\n",
    "        self.schema_json[\"name\"] = self.schema_name\n",
    "\n",
    "class activitySchema(baseSchema):\n",
    "    def fillJSON(self):\n",
    "        self.schema_json[\"@type\"] = \"https://schema.hbp.eu/minds/\"+self.schema_type+\".schema.json\"\n",
    "        self.schema_json[\"@id\"] = \"minds\"+ self.schema_dir.split(MINDSroot,1)[1] + \"/\" + self.schema_type + \"-\" + self.fileNum + \".json\"\n",
    "        self.schema_json[\"name\"] = self.schema_name\n",
    "        self.schema_json[\"approval\"] = [{\"@id\": \"minds/ethics/approval/v1.0.0/\"+file} for file in os.listdir(MINDSroot + \"/ethics/approval/v1.0.0\")]\n",
    "        self.schema_json[\"authority\"] = [{\"@id\": \"minds/ethics/authority/v1.0.0/\"+file} for file in os.listdir(MINDSroot + \"/ethics/authority/v1.0.0\")]\n",
    "        if self.schema_name == \"MRI-T1w\":\n",
    "            self.schema_json[\"methods\"] = [{\"@id\": \"minds/experiment/method/v1.0.0/method-001.json\"}]\n",
    "        elif self.schema_name == \"MRI-T2W\":\n",
    "            self.schema_json[\"methods\"] = [{\"@id\": \"minds/experiment/method/v1.0.0/method-002.json\"}]\n",
    "        elif self.schema_name == \"MRI-T2STAR\":\n",
    "            self.schema_json[\"methods\"] = [{\"@id\": \"minds/experiment/method/v1.0.0/method-003.json\"}]\n",
    "        elif self.schema_name == \"MRI-FLAIR\":\n",
    "            self.schema_json[\"methods\"] = [{\"@id\": \"minds/experiment/method/v1.0.0/method-004.json\"}]\n",
    "        elif self.schema_name == \"resting state fMRI\":\n",
    "            self.schema_json[\"methods\"] = [{\"@id\": \"minds/experiment/method/v1.0.0/method-005.json\"},\n",
    "                                           {\"@id\": \"minds/experiment/method/v1.0.0/method-08.json\"}]\n",
    "        elif self.schema_name == \"DWI\":\n",
    "            self.schema_json[\"methods\"] = [{\"@id\": \"minds/experiment/method/v1.0.0/method-006.json\"}]\n",
    "        elif self.schema_name == \"PET\":\n",
    "            self.schema_json[\"methods\"] = [{\"@id\": \"minds/experiment/method/v1.0.0/method-007.json\"}]\n",
    "\n",
    "        elif self.schema_name == \"DWI-ImageProcessing\": #(method#s: 6 & 9-15)\n",
    "            methodNums = [str(6).zfill(3)] \\\n",
    "                        + [str(i).zfill(3) for i in range(9,15+1)]\n",
    "            self.schema_json[\"methods\"] = [{\"@id\": \"minds/experiment/method/v1.0.0/method-{}.json\".format(i)} for i in methodNums]\n",
    "\n",
    "        elif self.schema_name == \"T1-imageProcessing\": #(method#s: 1 & 16-29)\n",
    "            methodNums = [str(1).zfill(3)] \\\n",
    "                        + [str(i).zfill(3) for i in range(16,29+1)]\n",
    "            self.schema_json[\"methods\"] = [{\"@id\": \"minds/experiment/method/v1.0.0/method-{}.json\".format(i)} for i in methodNums]\n",
    "\n",
    "        elif self.schema_name == \"rsfMRI-ImageProcessing\": #(method#s: 5 & 8 & 30-34 & 20 & 35 & 19 & 36-40)\n",
    "            methodNums = [str(i).zfill(3) for i in [5,8]] \\\n",
    "                        + [str(i).zfill(3) for i in range(30,34+1)] \\\n",
    "                        + [str(20).zfill(3)] \\\n",
    "                        + [str(35).zfill(3)] \\\n",
    "                        + [str(19).zfill(3)] \\\n",
    "                        + [str(i).zfill(3) for i in range(36,40+1)]\n",
    "            self.schema_json[\"methods\"] = [{\"@id\": \"minds/experiment/method/v1.0.0/method-{}.json\".format(i)} for i in methodNums]\n",
    "\n",
    "        elif self.schema_name == \"PET-ImageProcessing\": #(method#s: 7 & 41-44 & 34 & 22)\n",
    "            methodNums = [str(7).zfill(3)] \\\n",
    "                        + [str(i).zfill(3) for i in range(41,44+1)] \\\n",
    "                        + [str(34).zfill(3)] \\\n",
    "                        + [str(22).zfill(3)]\n",
    "            self.schema_json[\"methods\"] = [{\"@id\": \"minds/experiment/method/v1.0.0/method-{}.json\".format(i)} for i in methodNums]\n",
    "\n",
    "        elif self.schema_name == \"create cortical surface and region mapping\": #(method#s: 45-51)\n",
    "            methodNums = [str(i).zfill(3) for i in range(45,51+1)]\n",
    "            self.schema_json[\"methods\"] = [{\"@id\": \"minds/experiment/method/v1.0.0/method-{}.json\".format(i)} for i in methodNums]\n",
    "\n",
    "        elif self.schema_name == \"compute source space\":\n",
    "            methodNums = [str(i).zfill(3) for i in range(52,54+1)] #(method#s: 52-54)\n",
    "            self.schema_json[\"methods\"] = [{\"@id\": \"minds/experiment/method/v1.0.0/method-{}.json\".format(i)} for i in methodNums]\n",
    "\n",
    "        elif self.schema_name == \"compute BEM model & EEG locations\": #(method#s: 55-60)\n",
    "            methodNums = [str(i).zfill(3) for i in range(55,60+1)]\n",
    "            self.schema_json[\"methods\"] = [{\"@id\": \"minds/experiment/method/v1.0.0/method-{}.json\".format(i)} for i in methodNums]\n",
    "\n",
    "        elif self.schema_name == \"compute forward solution\": #(method#s: 61-63)\n",
    "            methodNums = [str(i).zfill(3) for i in range(61,63+1)]\n",
    "            self.schema_json[\"methods\"] = [{\"@id\": \"minds/experiment/method/v1.0.0/method-{}.json\".format(i)} for i in methodNums]\n",
    "\n",
    "        elif self.schema_name == \"save derivatives accoording to TVB specifications\": # (method#: 64-70)\n",
    "            methodNums = [str(i).zfill(3) for i in range(64,70+1)]\n",
    "            self.schema_json[\"methods\"] = [{\"@id\": \"minds/experiment/method/v1.0.0/method-{}.json\".format(i)} for i in methodNums]\n",
    "\n",
    "        elif self.schema_name == \"PhenotypicandAssessmentData\": #(method#s: 71-81)\n",
    "            methodNums = [str(i).zfill(3) for i in range(71,81+1)]\n",
    "            self.schema_json[\"methods\"] = [{\"@id\": \"minds/experiment/method/v1.0.0/method-{}.json\".format(i)} for i in methodNums]\n",
    "\n",
    "        self.schema_json[\"preparation\"] = [{\"@id\": \"minds/core/preparation/v1.0.0/\"+file} for file in os.listdir(MINDSroot + \"/core/preparation/v1.0.0\")]\n",
    "\n",
    "class agecategorySchema(baseSchema):\n",
    "    def fillJSON(self):\n",
    "        self.schema_json[\"@type\"] = \"https://schema.hbp.eu/minds/\"+self.schema_type+\".schema.json\"\n",
    "        self.schema_json[\"@id\"] = \"minds\"+ self.schema_dir.split(MINDSroot,1)[1] + \"/\" + self.schema_type + \"-\" + self.fileNum + \".json\"\n",
    "        self.schema_json[\"name\"] = self.schema_name\n",
    "\n",
    "class specimengroupSchema(baseSchema):\n",
    "    def fillJSON(self):\n",
    "        self.schema_json[\"@type\"] = \"https://schema.hbp.eu/minds/\"+self.schema_type+\".schema.json\"\n",
    "        self.schema_json[\"@id\"] = \"minds\"+ self.schema_dir.split(MINDSroot,1)[1] + \"/\" + self.schema_type + \"-\" + self.fileNum + \".json\"\n",
    "        self.schema_json[\"name\"] = self.schema_name\n",
    "        self.schema_json[\"subjects\"] = []\n",
    "\n",
    "\n",
    "class subjectSchema(baseSchema):\n",
    "    def fillJSON(self):\n",
    "        self.schema_json[\"@type\"] = \"https://schema.hbp.eu/minds/\"+self.schema_type+\".schema.json\"\n",
    "        self.schema_json[\"@id\"] = \"minds\"+ self.schema_dir.split(MINDSroot,1)[1] + \"/\" + self.schema_name + \".json\"\n",
    "        self.schema_json[\"name\"] = \"HCP_sub-\" + self.schema_name\n",
    "        participants_tsv = pd.read_csv(BIDSroot + \"/participants.tsv\", sep='\\t',dtype={'participant_id': str})\n",
    "        self.schema_json[\"age\"] = str(participants_tsv[participants_tsv[\"participant_id\"]==self.schema_name][\"Age\"].item()) + \" years\"\n",
    "        self.schema_json[\"ageCategory\"] = [{\"@id\" : \"minds/core/agecategory/v1.0.0/97eaac65-ec72-4435-9e20-5b2308076060\"}] #if participants_tsv[participants_tsv[\"participant_id\"]==self.schema_name][\"Age\"].item() > 18 else []\n",
    "        self.schema_json[\"sex\"] = [{\"@id\" : \"minds/core/sex/v1.0.0/85ba5561-e9bf-41a8-b0fe-bd17ae0f7b2c\"}] if participants_tsv[participants_tsv[\"participant_id\"]==self.schema_name][\"Sex\"].item() == \"M\" else [{\"@id\" : \"minds/core/sex/v1.0.0/f7c82ad1-b4ba-495a-ba81-145d8dbf82ea\"}]\n",
    "        self.schema_json[\"species\"] = [{\"@id\" : \"minds/core/species/v1.0.0/0ea4e6ba-2681-4f7d-9fa9-49b915caaac9\"}]\n",
    "    def writeJSON(self): #overwrite baseSchema \"writeJSON\". #name by subject ID.\n",
    "        with open(self.schema_dir+\"/\"+\"HCP_sub-\"+self.schema_name.replace(\" \",\"\")+\".json\",\"w\") as f:\n",
    "            json.dump(self.schema_json, f, indent=4)\n",
    "\n",
    "class datasetSchema(baseSchema):\n",
    "    def fillJSON(self):\n",
    "        self.schema_json[\"@type\"] = \"https://schema.hbp.eu/minds/\"+self.schema_type+\".schema.json\"\n",
    "        self.schema_json[\"@id\"] = \"minds\"+ self.schema_dir.split(MINDSroot,1)[1] + \"/\" + self.schema_type + \"-\" + self.fileNum + \".json\"\n",
    "        self.schema_json[\"name\"] = self.schema_name\n",
    "        self.schema_json[\"description\"] = \"This data set contains structural and functional connectivity and region-average fMRI time series from 785 participants of the Human Connectome Project (HCP) S900 data set. HCP builds network maps (connectomes) of the human brain and provides data for research into brain disorders, but also seeks to understand healthy brains and developmental processes. HCP uses non-invasive imaging technologies: resting-state fMRI, task-based fMRI, MEG, diffusion MRI and also performs behavioral and genetic testing. Data was acquired using customized sequences with high spatial and temporal resolution: 2 mm isotropic voxel size and a TR of 720 ms for fMRI and 1.25 mm isotropic voxel size and a diffusion weighting of up to b = 3000 s/mm2 and >=128 unique directions for dwMRI. HCP's minimal preprocessing pipelines were used for preprocessing, involving distortion removal, surface mapping, registration, and alignment to standard space. Correction of EPI and eddy-current distortions uses phase-encoding direction-reversed images for each diffusion direction. Region-parcellation is based on HCP's Glasser/MMP1 atlas. Full-brain tractography with 25 Million produced tracks yielded structural connectomes.\",\n",
    "#        self.schema_json[\"owners\"] = [{\"@id\": \"minds/core/person/v1.0.0/\"+os.listdir(MINDSroot + \"/core/person/v1.0.0\")[0]}],\n",
    "#        self.schema_json[\"contributors\"] = [ {\"@id\": \"minds/core/person/v1.0.0/\"+file} for file in os.listdir(MINDSroot + \"/core/person/v1.0.0\")],\n",
    "        self.schema_json[\"embargoStatus\"] = \"minds/core/embargostatus/v1.0.0/1d726b76-b176-47ed-96f0-b4f2e17d5f19\",\n",
    "        self.schema_json[\"license\"] = [{\"@id\": \"licenses/core/information/v1.0.0/7377a480-6066-4c47-9be8-67c586713ed7\"}],\n",
    "#        self.schema_json[\"activities\"] = [{\"@id\": \"minds/core/activity/v1.0.0\"+\"/\"+file} for file in os.listdir(MINDSroot + \"/core/activity/v1.0.0\")]\n",
    "        self.schema_json[\"specimenGroups\"] = [{\"@id\": \"minds/core/specimengroups/v1.0.0\"+\"/\"+file} for file in os.listdir(MINDSroot + \"/core/specimengroup/v1.0.0\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify schemas and write out openMINDS metadata\n",
    "Here we define what key-value pairs shall appear in each JSON schema. (Un)comment according to data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## III. Specify schemas and instances. Fill & create JSONs using the functions/classes specified above.\n",
    "##### person\n",
    "#person_schema = {\n",
    "#    \"@type\": \"\",\n",
    "#    \"@id\": \"\",\n",
    "#    \"name\": \"\",\n",
    "#    \"shortName\": \"\",\n",
    "#}\n",
    "#\n",
    "#person_vec = [\"Pai, Roopa Kalsank\", \"Doe, John\", \"Doe, Jane\"]\n",
    "#\n",
    "##for person_name in person_vec:\n",
    "##    person = openMINDSschemaWriter(\"person\", MINDSroot, \"/core/person/v1.0.0\", person_name, person_schema, BIDSroot)\n",
    "##    person.fillJSON()\n",
    "##    person.writeJSON()\n",
    "#\n",
    "\n",
    "##### ethics authority\n",
    "#authority_schema = {\n",
    "#  \"@type\": \"\",\n",
    "#  \"@id\": \"\",\n",
    "#  \"name\": \"\"\n",
    "#}\n",
    "#authority_vec = [\"Ethics Board of ABC University\"]\n",
    "#\n",
    "#for authority_name in authority_vec:\n",
    "#    authority = openMINDSschemaWriter(\"authority\", MINDSroot, \"/ethics/authority/v1.0.0\", authority_name, authority_schema, BIDSroot)\n",
    "#    authority.fillJSON()\n",
    "#    authority.writeJSON()\n",
    "#\n",
    "##### ethics approval\n",
    "#approval_schema = {\n",
    "#    \"@type\": \"\",\n",
    "#    \"@id\": \"\",\n",
    "#    \"name\": \"\",\n",
    "#    \"generatedBy\": []\n",
    "#}\n",
    "#approval_vec = [\"EA/ID/01\"]\n",
    "#\n",
    "#for approval_name in approval_vec:\n",
    "#    approval = openMINDSschemaWriter(\"approval\", MINDSroot, \"/ethics/approval/v1.0.0\", approval_name, approval_schema, BIDSroot)\n",
    "#    approval.fillJSON()\n",
    "#    approval.writeJSON()\n",
    "#\n",
    "##### method\n",
    "##1. Depends on how many modalities you include / which processing stages you include.\n",
    "##2. this script includes acquisition, image processing, creation of TVB-format files & phenotypic/assessment data.\n",
    "##3. if user edits this, user will also need to edit \"activity-methodrange\" relationships in the activity schema in Part II.\n",
    "#\n",
    "#method_schema = {\n",
    "#    \"@type\": \"\",\n",
    "#    \"@id\": \"\",\n",
    "#    \"name\": \"\"\n",
    "#}\n",
    "#\n",
    "#method_vec = [#acquisition\n",
    "#              \"T1-weighted magnetic resonance imaging (T1w-MRI)\",\n",
    "#              \"T2-weighted magnetic resonance imaging (T2w-MRI)\",\n",
    "#              \"...\"\n",
    "#             ]\n",
    "#for i,method_name in enumerate(method_vec):\n",
    "#    method = openMINDSschemaWriter(\"method\", MINDSroot, \"/experiment/method/v1.0.0\", method_name, method_schema, BIDSroot,IRI_vec[i])\n",
    "#    method.fillJSON()\n",
    "#    method.writeJSON()\n",
    "#\n",
    "##### activity\n",
    "## One *activity* needed for each *method*. Multiple *methods* can combine to create an *activity*. e.g. fMRI (method) + resting state (method) = resting state fMRI (activity)\n",
    "#\n",
    "#activity_schema = {\n",
    "#    \"@type\": \"\",\n",
    "#    \"@id\": \"\",\n",
    "#    \"name\": \"\",\n",
    "#    \"approval\": [],\n",
    "#    \"authority\": [],\n",
    "#    \"methods\": [],\n",
    "#    \"preparation\":[]\n",
    "#}\n",
    "#\n",
    "#activity_vec = [#acquisition\n",
    "#                \"MRI-T1w\",\n",
    "#                \"MRI-T2W\",\n",
    "#                \"MRI-T2STAR\",\n",
    "#                \"MRI-FLAIR\",\n",
    "#                \"resting state fMRI\",\n",
    "#                \"DWI\",\n",
    "#                \"PET\",\n",
    "#                #processing\n",
    "#                \"DWI-ImageProcessing\",\n",
    "#                \"T1-ImageProcessing\",\n",
    "#                \"rsfMRI-ImageProcessing\"\n",
    "#                \"PET-ImageProcessing\",\n",
    "#\n",
    "#                #reorganize script/create TVB input files\n",
    "#                \"create cortical surface and region mapping\"\n",
    "#                \"compute source space\",\n",
    "#                \"compute BEM model & EEG locations\",\n",
    "#                \"compute forward solution\",\n",
    "#                \"save derivatives accoording to TVB specifications\",\n",
    "#\n",
    "#                # phenotypic data\n",
    "#                \"PhenotypicandAssessmentData\"\n",
    "#                ]\n",
    "##vec order important\n",
    "#\n",
    "#for activity_name in activity_vec:\n",
    "#    activity = openMINDSschemaWriter(\"activity\", MINDSroot, \"/core/activity/v1.0.0\", activity_name, activity_schema, BIDSroot)\n",
    "#    activity.fillJSON()\n",
    "#    activity.writeJSON()\n",
    "#\n",
    "##### age category\n",
    "#agecat_schema = {\n",
    "#  \"@type\": \"\",\n",
    "#  \"@id\": \"\",\n",
    "#  \"name\": \"\"\n",
    "#}\n",
    "#age_vec = [\"22-25\",\"26-30\",\"31-35\",\"36-122\"]\n",
    "#\n",
    "#for agecat_name in age_vec:\n",
    "#    agecat = openMINDSschemaWriter(\"agecategory\", MINDSroot, \"/core/agecategory/v1.0.0\", agecat_name, agecat_schema, #BIDSroot)\n",
    "#    agecat.fillJSON()\n",
    "#    agecat.writeJSON()\n",
    "\n",
    "##### specimen group\n",
    "specimengroup_schema = {\n",
    "  \"@type\": \"\",\n",
    "  \"@id\": \"\",\n",
    "  \"name\": \"\",\n",
    "  \"subjects\": []\n",
    "}\n",
    "\n",
    "specimengroup_vec = [\"Cognitively Normal (CN)\"]\n",
    "\n",
    "for specimengroup_name in specimengroup_vec:\n",
    "    specimengroup = openMINDSschemaWriter(\"specimengroup\", MINDSroot, \"/core/specimengroup/v1.0.0\", specimengroup_name, specimengroup_schema, BIDSroot)\n",
    "    specimengroup.fillJSON()\n",
    "    specimengroup.writeJSON()\n",
    "\n",
    "\n",
    "#### subject\n",
    "subject_schema = {\n",
    "  \"@type\": \"\",\n",
    "  \"@id\": \"\",\n",
    "  \"name\": \"\",\n",
    "  \"age\": \"\",\n",
    "  \"ageCategory\": [],\n",
    "  \"sex\": [],\n",
    "  \"species\": []\n",
    "}\n",
    "    \n",
    "subject_vec = [sub for sub in participants_tsv[\"participant_id\"].tolist()]\n",
    "\n",
    "for subject_name in subject_vec:\n",
    "    subject = openMINDSschemaWriter(\"subject\", MINDSroot, \"/experiment/subject/v1.0.0\", subject_name, subject_schema, BIDSroot)\n",
    "    subject.fillJSON()\n",
    "    subject.writeJSON()\n",
    "\n",
    "#### loop back and add relevant data to specimen group JSONs\n",
    "for sg_JSON_file in os.listdir(MINDSroot + \"/core/specimengroup/v1.0.0\"):\n",
    "    with open(MINDSroot + \"/core/specimengroup/v1.0.0\"+\"/\"+sg_JSON_file,\"r\") as f:\n",
    "        sg_JSON_data = json.load(f)\n",
    "        sg_name = sg_JSON_data[\"name\"]\n",
    "        if \"CN\" in sg_name:\n",
    "            for sub in participants_tsv[\"participant_id\"].tolist():\n",
    "                sg_JSON_data[\"subjects\"].append({\"@id\": \"minds/experiment/subject/v1.0.0/HCP_sub-\" +sub+\".json\"})\n",
    "#        elif \"MCI\" in sg_name:\n",
    "#            for sub in participants_tsv[\"participant_id\"].tolist():\n",
    "#                if \"MCI\" in participants_tsv[participants_tsv[\"participant_id\"]==sub][\"Research Group\"].item():\n",
    "#                    sg_JSON_data[\"subjects\"].append({\"@id\": \"minds/experiment/subject/v1.0.0/\"+sub+\".json\"})\n",
    "#        elif \"AD\" in sg_name:\n",
    "#            for sub in participants_tsv[\"participant_id\"].tolist():\n",
    "#                if participants_tsv[participants_tsv[\"participant_id\"]==sub][\"Research Group\"].item() == \"AD\":\n",
    "#                    sg_JSON_data[\"subjects\"].append({\"@id\": \"minds/experiment/subject/v1.0.0/\"+sub+\".json\"})\n",
    "    with open(MINDSroot + \"/core/specimengroup/v1.0.0\"+\"/\"+sg_JSON_file,\"w\") as f:\n",
    "        json.dump(sg_JSON_data, f, indent=4)\n",
    "\n",
    "#### finally, write the dataset JSON\n",
    "#Notes/assumptions:\n",
    "#1. owners: default: first \"person\"\n",
    "#2. contributors: all persons\n",
    "#3. embargoStatus: leave as is for now\n",
    "#4. license: leave as is for now\n",
    "#5. description: hardcode or editable? for the moment, hardcode inside class definition. if other schemas also take descriptions, add \"description\" as function argument.\n",
    "\n",
    "dataset_schema = {\n",
    "  \"@type\": \"\",\n",
    "  \"@id\": \"\",\n",
    "  \"name\": \"\",\n",
    "  \"description\": \"\",\n",
    "  \"owners\": [],\n",
    "  \"contributors\": [],\n",
    "  \"embargoStatus\": \"\",\n",
    "#  \"license\": [],\n",
    "#  \"activities\": [],\n",
    "  \"specimenGroups\": []\n",
    "}\n",
    "\n",
    "dataset_vec = [\"Human Connectome Project Young Adult Structural Connectomes, Functional Connectomes and fMRI time series for connectome analsis and brain network modelling\"]\n",
    "\n",
    "for dataset_name in dataset_vec:\n",
    "    dataset = openMINDSschemaWriter(\"dataset\", MINDSroot, \"/core/dataset/v1.0.0\", dataset_name, dataset_schema, BIDSroot)\n",
    "    dataset.fillJSON()\n",
    "    dataset.writeJSON()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
